from snakemake import shell
import numpy as np
import itertools
import pandas as pd
import os
import csv

metadata = pd.read_csv('config/metadata.tsv', header=0, sep='\t')
metadata = metadata+"_R1"
temp_dict = pd.DataFrame.to_dict(metadata, orient='list')

d = dict(zip(temp_dict['ip'], temp_dict['input'])) # dictionary with ip as keys and input as values
peakcallers = ['macs2','spp', 'spp2']
d["SRR567586"] = "SRR567585"
d["dc92_bg3_ctcf-56"] = "dc91_bg3_input"
d["dc94_bg3_ctcf-59"] = "dc93_bg3_input"

chr = ["chr2L", "chr2R", "chr3L", "chr3R"]

d = {
    "SRR567586" : "SRR567585",    
    "lm06_kc_shep-gp_R1" : "lm09_kc_input_R1",
    "lm07_kc_shep-r5_R1" : "lm09_kc_input_R1",
    "lm08_kc_shep-r6_R1" : "lm09_kc_input_R1",
    "lm10_kc_shep-gp_R1" : "lm09_kc_input_R1",
    "lm32_kc_suhw_R1" : "lm09_kc_input_R1",
    "lm33_bg3_suhw_R1" : "lm31_bg3_input_R1",
    "lm34_bg3_shep-gp_R1" : "lm31_bg3_input_R1",
    "lm36_bg3_shep-r6_R1" : "lm31_bg3_input_R1",
    "lm37_kc_mod-gp_R1" : "lm09_kc_input_R1",
    "lm38_kc_mod-rb_R1" : "lm09_kc_input_R1",
    "lm43_bg3_mod-gp_R1" : "lm31_bg3_input_R1",
    "lm44_bg3_mod-rb_R1" : "lm31_bg3_input_R1",
    "sjl_kc_cp190_R1" : "sjl_kc_input_R1",
    "sjl_s2_shep_R1" : "sjl_s2_input_R1",
    "sjl_s3_suhw_R1" : "sjl_s3_input_R1",
#    "sjl_s3_shep_R1" : "sjl_s3_input_R1",
#    "dc92_bg3_ctcf-56" : "dc91_bg3_input",
#    "dc94_bg3_ctcf-59" : "dc93_bg3_input"
}

sample = [str(i) for i in d.keys()]

q_value = [] # Keep track of the q_values we'll test on
q_value = np.logspace(-15, -.0005, num=10)

# Now make lists of the parameters we will be adjusting
llocal = [i for i in range(8000, 16000, 2000)] # Keep track of the llocal values we'll test on
slocal = [i for i in range(800, 1600, 200)] # Same for the slocal values
downsample = ["ds", "no-ds"] # Whether to use the --down-sample argument
nolambda = ["nl", "no-nl"] # Whether to use the --nolambda argument
tolarge = ["tl", "no-tl"] # Whether to use --tolarge
lowmfold = [2, 3,4,5,6,7,8] # The lower boundary for the mfold
highmfold = [i for i in range(30,60,10)] # The upper boundary for the mfold

# q_value = [.03, .04, .05, .06, .07]
# llocal = [5000, 10000, 15000]
# highmfold = [30, 40, 50, 60, 70]
# slocal = [500, 1000, 1500]
# lowmfold = [3, 4, 5, 6, 7]
# nolambda = ["no-nl"]
# q_value = [.05]
# llocal = [10000]
# highmfold = [50]
# slocal = [1000]
# lowmfold = [5]
# nolambda = ["no-nl"]
# tolarge = ["no-tl"]

peakerror = (
    expand(
        ("peakerror/macs2/{sample}/q_value_{q_value}/"
        "llocal_{llocal}/slocal_{slocal}/lowmfold_{lowmfold}"
        "/highmfold_{highmfold}/{nolambda}/{downsample}/{tolarge}"
        "/{chr}/{sample}_errors.tsv"),
        q_value = q_value,
        llocal = llocal,
        slocal = slocal,
        lowmfold = lowmfold,
        highmfold = highmfold,
        nolambda = nolambda,
        tolarge = tolarge,
        downsample = downsample,
        sample = sample,
        chr = chr,
    ) +
    ["peakerror/summary.tsv"] +
    ["peakerror/optimal/optimal_ca.csv",
    "peakerror/optimal/optimal_sample.csv"] +
    expand(
        ("peakerror/macs2/{sample}/q_value_{q_value}/"
        "llocal_{llocal}/slocal_{slocal}/lowmfold_{lowmfold}"
        "/highmfold_{highmfold}/{nolambda}/{downsample}/{tolarge}"
        "/combined.tsv"),
        q_value = q_value,
        llocal = llocal,
        slocal = slocal,
        lowmfold = lowmfold,
        highmfold = highmfold,
        nolambda = nolambda,
        downsample = downsample,
        tolarge = tolarge,
        sample = sample,
    ) +
    ["peakerror/confusion/confusion.csv"]
)

bedtools = (
       expand("peakerror/intersect/{{sample}}/all_combinations.bed",
           sample = sample)
       )

feature = (

        expand("feature/spectrogram/{sample}.tsv",
            sample = sample) +
    ["multiqc/all"] +
    expand("fingerprints/{sample}.pdf", sample=sample) +
    expand("fingerprints/{sample}_counts.tab", sample=sample) +
    expand("fingerprints/{sample}_qc.tab", sample=sample) +
    ["forest/forest.csv", "svm/svm.csv"]
)


rule all:
    input: peakerror

rule macs2:
    input:
        ip = "bam/{sample}.bam",
        inp = lambda wc: "bam/{0}.bam".format(d[wc.sample])
    output:
        narrowPeak = ("peak_out/macs2/{sample}/q_value_{q_value}/llocal_{llocal}/"
        "slocal_{slocal}/lowmfold_{lowmfold}/highmfold_{highmfold}/"
        "{nolambda}/{downsample}/{tolarge}/{sample}_peaks.narrowPeak")
    params:
        outdir_prefix = ("peak_out/macs2/{sample}/q_value_{q_value}/llocal_{llocal}/"
        "slocal_{slocal}/lowmfold_{lowmfold}/highmfold_{highmfold}/{nolambda}/{downsample}/{tolarge}"),
        sample_prefix = "peak_out/macs2/{sample}/q_value_{q_value}/{sample}",
        q_val = "{q_value}",
        llocal = "{llocal}",
        slocal = "{slocal}",
        lowmfold = "{lowmfold}",
        highmfold = "{highmfold}",
        downsample = "{downsample}",
        nolambda = "{nolambda}",
        tolarge = "{tolarge}"
    wrapper:
        "file:wrappers/macs2"

rule regex:
    input:
        ("peak_out/macs2/{sample}/q_value_{q_value}/llocal_{llocal}/"
        "slocal_{slocal}/lowmfold_{lowmfold}/highmfold_{highmfold}/"
        "{nolambda}/{downsample}/{tolarge}/{sample}_peaks.narrowPeak")
    output:
        ("peak_out/macs2/{sample}/q_value_{q_value}/llocal_{llocal}/"
        "slocal_{slocal}/lowmfold_{lowmfold}/highmfold_{highmfold}/"
        "{nolambda}/{downsample}/{tolarge}/{chr}/{sample}_peaks.narrowPeak.threecolumns")
    params:
        chr = "{chr}"
    shell:
        """awk '{{OFS="\t"; print $1,$2,$3}}' {input} | grep '^{params.chr}.*$' -u | sort -k2 -n | awk '!seen[$0]++' > {output}"""

d2 = {
    "SRR567586" : "bg3_suhw",
    "el39_bg3_rump-5g4_R1" : "bg3_rump",
    "el40_kc_rump-5g4_R1" : "kc_rump",
    "el41_bg3_rump-5g4_R1" : "bg3_rump",
    "el42_kc_rump-10c3_R1" : "kc_rump",
    "lm06_kc_shep-gp_R1" : "kc_shep",
    "lm07_kc_shep-r5_R1" : "kc_shep",
    "lm08_kc_shep-r6_R1" : "kc_shep",
    "lm10_kc_shep-gp_R1" : "kc_shep",
    "lm32_kc_suhw_R1" : "kc_suhw",
    "lm33_bg3_suhw_R1" : "bg3_suhw",
    "lm34_bg3_shep-gp_R1" : "bg3_shep",
    "lm36_bg3_shep-r6_R1" : "bg3_shep",
    "lm37_kc_mod-gp_R1" : "kc_mod",
    "lm38_kc_mod-rb_R1" : "kc_mod",
    "lm39_kc_rm62-rat_R1" : "kc_rm62",
    "lm40_kc_rm62-rb_R1" : "kc_rm62",
    "lm41_kc_rump-5g4_R1" : "kc_rump",
    "lm42_kc_rump-10c3_R1" : "kc_rump",
    "lm43_bg3_mod-gp_R1" : "bg3_mod",
    "lm44_bg3_mod-rb_R1" : "bg3_mod",
    "lm47_bg3_rump5g4_R1" : "bg3_rump",
    "lm48_bg3_rump-10c3_R1" : "bg3_rump",
    "sjl_cl8_cp190_R1" : "cl8_cp190",
    "sjl_cl8_mod_R1" : "cl8_mod",
    "sjl_cl8_suhw_R1" : "cl8_suhw",
    "sjl_kc_cp190_R1" : "kc_cp190",
    "sjl_mbn2_cp190_R1" : "mbn2_cp190",
    "sjl_mbn2_mod_R1" : "mbn2_mod",
    "sjl_mbn2_shep_R1" : "mbn2_shep",
    "sjl_mbn2_suhw_R1" : "mbn2_suhw",
    "sjl_s2_cp190_R1" : "s2_cp190",
    "sjl_s2_mod_R1" : "s2_mod",
    "sjl_s2_shep_R1" : "s2_shep",
    "sjl_s3_shep_R1" : "s3_shep",
    "sjl_s3_suhw_R1" : "s3_suhw",
    "dc92_bg3_ctcf-56" : "bg3_ctcf",
    "dc94_bg3_ctcf-59" : "bg3_ctcf"
    }

rule peakerror_compute:
    input:
        sample = ("peak_out/macs2/{sample}/q_value_{q_value}/llocal_{llocal}/"
        "slocal_{slocal}/lowmfold_{lowmfold}/highmfold_{highmfold}/"
        "{nolambda}/{downsample}/{tolarge}/{chr}/{sample}_peaks.narrowPeak.threecolumns"),
        labels = lambda wc: "peakerror/labels/{0}/{1}labels.bed".format(d2[wc.sample], wc.chr)
    output:
        ("peakerror/macs2/{sample}/q_value_{q_value}/llocal_{llocal}/"
        "slocal_{slocal}/lowmfold_{lowmfold}/highmfold_{highmfold}/"
        "{nolambda}/{downsample}/{tolarge}/{chr}/{sample}_errors.tsv")
    shell:
        ("python peakerror/PeakError.py {input.sample} "
        "{input.labels} {output}")

rule chrom_combine: # Combine each chromosome arm into a single file.
    input:
        expand("peakerror/macs2/{{sample}}/q_value_{{q_value}}/llocal_{{llocal}}/"
        "slocal_{{slocal}}/lowmfold_{{lowmfold}}/highmfold_{{highmfold}}/"
        "{{nolambda}}/{{downsample}}/{{tolarge}}/{chr}/{{sample}}_errors.tsv", chr=chr)
    output:
        ("peakerror/macs2/{sample}/q_value_{q_value}/"
        "llocal_{llocal}/slocal_{slocal}/lowmfold_{lowmfold}"
        "/highmfold_{highmfold}/{nolambda}/{downsample}/{tolarge}"
        "/combined.tsv"),
    wrapper:
        "file:wrappers/chrom_combine"

rule peakerror_analyze: # Analyze the output to create a table of mcc values for each parameter combination.
    input:
        expand("peakerror/macs2/{sample}/q_value_{q_value}/llocal_{llocal}/"
        "slocal_{slocal}/lowmfold_{lowmfold}/highmfold_{highmfold}/"
        "{nolambda}/{downsample}/{tolarge}/combined.tsv", sample=sample, q_value=q_value,
        llocal=llocal, slocal=slocal, lowmfold=lowmfold, highmfold=highmfold,
        nolambda=nolambda, downsample=downsample, tolarge=tolarge)
    output:
        "peakerror/summary.tsv"
    wrapper:
        "file:wrappers/peakerror_analyze"

rule intersect:
    input:
        default = ("peak_out/macs2/{{sample}}/q_value_0.05/llocal_10000/" 
        "slocal_1000/lowmfold_5/highmfold_50/no-nl/no-ds/{{sample}}_peaks.narrowPeak"),
        combinations = expand("peak_out/macs2/{{sample}}/q_value_{q_value}/llocal_{llocal}/"
        "slocal_{slocal}/lowmfold_{lowmfold}/highmfold_{highmfold}/"
        "{nolambda}/{downsample}/{{sample}}_peaks.narrowPeak", q_value=q_value,
        llocal=llocal, slocal=slocal, lowmfold=lowmfold, highmfold=highmfold,
        nolambda=nolambda, downsample=downsample, tolarge=tolarge)
    output:
       "peakerror/intersect/{{sample}}/all_combinations.bed"
    wrapper:
        "file:wrappers/intersect"

rule optimal:
    input: "peakerror/summary.csv"
    output: 
        ca = "peakerror/optimal_ca.csv",
        sample = "peakerror/optimal_sample.csv"
    wrapper:
        "file:wrappers/optimal"

rule confusion:
    input: "peakerror/summary.tsv"
    output: "peakerror/confusion/confusion.csv"
    wrapper: "file:wrappers/confusion"

rule spectrogram: # Return the spectrogram signal, frequency, and time values for each sample
    input: "coverage/{sample}.bw"
    output: "feature/spectrogram/{sample}.tsv"
    shell: "python feature/fourier.py {input} {output}"

rule multiqc:
    input:
        fastqc = expand("fastqc/{sample}_fastqc.zip", sample=sample),
        markduplicates = expand("dedup/{sample}.bam", sample=sample)
    output:
        "multiqc/all"
    wrapper:
        "file:wrappers/multiqc"

rule plot_fingerprint:
    input:
        ip_bam = "dedup/{sample}.bam",
        inp_bam = lambda wc: "dedup/{0}.bam".format(d[wc.sample]),
    output:
        plot = "fingerprints/{sample}.pdf",
        counts = "fingerprints/{sample}_counts.tab",
        qc = "fingerprints/{sample}_qc.tab"
    conda: "wrappers/plot_fingerprint/environment.yaml"
    shell:
        "plotFingerprint -b {input.ip_bam} "
        "{input.inp_bam} "
        "-plot {output.plot} "
        "--outRawCounts {output.counts} "
        "--outQualityMetrics {output.qc}" 

rule cross_correlation: # Extract MACS cross-correlation values while deconvolving them to get the fragment length distribution
    input:
        ("peak_out/macs2/{sample}/q_value_{q_value}/"
        "llocal_{llocal}/slocal_{slocal}/lowmfold_{lowmfold}/"
        "highmfold_{highmfold}/{nolambda}/{downsample}/{tolarge}/"
        "{sample}_model.r")
    output:
        "cross_correlation/cross_correlation.tsv"
    wrapper:
        "file:wrappers/cross_correlation"

rule filesize: # Calculate the ratio of size of ip to size of input.
    input:
        ip_bam = "dedup/{sample}.bam",
        inp_bam = lambda wc: "dedup/{0}.bam".format(d[wc.sample])
    output:
        filesize = "filesize/filesize.csv"
    wrapper:
        "file:wrappers/filesize"

rule feature_combine: # Use this to collect all the information that we use as features for which we can run feature tests on.
    input:
        fingerprint_counts  = "fingerprints/{sample}_counts.tab",
        qc  = "fingerprints/{sample}_qc.tab",
        spec = "feature/spectrogram/{sample}.tsv",
        multiqc = "multiqc/all/multiqc_data/multiqc_general_stats.txt",
        cross_correlation = "cross_correlation/cross_correlation.tsv",
        filesize = "filesize/filesize.csv",
    output: 
        forest_input = "feature/feature_forest_input.csv",
        svm_input = "feature/svm_input.csv"
    wrapper:
        "file:wrappers/feature_combine"

rule random_forest_classifier:
    input:
        "feature/feature_forest_input.csv"
    output:
        "forest/forest.csv"
    wrapper:
        "file:wrappers/random_forest_classifier"

rule svm:
    input:
        "feature/feature_svm_input.csv"
    output:
        "svm/svm.csv"
    wrapper:
        "file:wrappers/svm"

rule pca:
    input:
        "feature/feature_pca_input.csv"
    output:
        "pca/pca.csv"
    wrapper:
        "file:wrappers/pca"

# vim: ft=python
